\relax 
\citation{hastie2009elements,lecun2015deep}
\citation{silver2016mastering}
\citation{chatgpt}
\citation{mcculloch1943logical}
\citation{rosenblatt1958perceptron}
\citation{rumelhart1985learning}
\citation{williams1989learning,sutskever2014sequence}
\citation{hochreiter1997long,chung2014empirical}
\citation{poole2014analyzing}
\citation{neelakantan2015adding}
\citation{luo2016understanding}
\citation{srivastava2014dropout}
\citation{szegedy2013intriguing}
\citation{goodfellow2014explaining}
\citation{carlini2017towards}
\citation{jiang2020beyond}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\citation{lieu2022adaptive}
\citation{salle2014efficient}
\citation{liu2010stochastic}
\citation{gan2015valuation}
\citation{broadie2015risk}
\citation{hong2017kernel}
\citation{zhang2022sample}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem Formulation}{3}{}\protected@file@percent }
\newlabel{sec:problem-formulation}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Two-Stage Nested Simulation with Deep Neural Network Metamodels}{3}{}\protected@file@percent }
\newlabel{sec:metamodel2Stage}{{3}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}One-Stage Nested Simulation with Deep Neural Network Metamodels}{3}{}\protected@file@percent }
\newlabel{sec:metamodel1Stage}{{4}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical Results}{3}{}\protected@file@percent }
\newlabel{sec:numerical}{{5}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{3}{}\protected@file@percent }
\newlabel{sec:conclusion}{{6}{3}}
\bibstyle{plainnat}
\bibdata{refP2}
\bibcite{broadie2015risk}{{1}{2015}{{Broadie et~al.}}{{Broadie, Du, and Moallemi}}}
\bibcite{carlini2017towards}{{2}{2017}{{Carlini and Wagner}}{{}}}
\bibcite{chung2014empirical}{{3}{2014}{{Chung et~al.}}{{Chung, Gulcehre, Cho, and Bengio}}}
\bibcite{gan2015valuation}{{4}{2015}{{Gan and Lin}}{{}}}
\bibcite{goodfellow2014explaining}{{5}{2014}{{Goodfellow et~al.}}{{Goodfellow, Shlens, and Szegedy}}}
\bibcite{hastie2009elements}{{6}{2009}{{Hastie et~al.}}{{Hastie, Tibshirani, and Friedman}}}
\bibcite{hochreiter1997long}{{7}{1997}{{Hochreiter and Schmidhuber}}{{}}}
\bibcite{hong2017kernel}{{8}{2017}{{Hong et~al.}}{{Hong, Juneja, and Liu}}}
\bibcite{jiang2020beyond}{{9}{2020}{{Jiang et~al.}}{{Jiang, Huang, Liu, and Yang}}}
\bibcite{lecun2015deep}{{10}{2015}{{LeCun et~al.}}{{LeCun, Bengio, and Hinton}}}
\bibcite{lieu2022adaptive}{{11}{2022}{{Lieu et~al.}}{{Lieu, Nguyen, Dang, Lee, Kang, and Lee}}}
\bibcite{liu2010stochastic}{{12}{2010}{{Liu and Staum}}{{}}}
\bibcite{luo2016understanding}{{13}{2016}{{Luo et~al.}}{{Luo, Li, Urtasun, and Zemel}}}
\bibcite{mcculloch1943logical}{{14}{1943}{{McCulloch and Pitts}}{{}}}
\bibcite{neelakantan2015adding}{{15}{2015}{{Neelakantan et~al.}}{{Neelakantan, Vilnis, Le, Sutskever, Kaiser, Kurach, and Martens}}}
\bibcite{chatgpt}{{16}{2023}{{OpenAI}}{{}}}
\bibcite{poole2014analyzing}{{17}{2014}{{Poole et~al.}}{{Poole, Sohl-Dickstein, and Ganguli}}}
\bibcite{rosenblatt1958perceptron}{{18}{1958}{{Rosenblatt}}{{}}}
\bibcite{rumelhart1985learning}{{19}{1985}{{Rumelhart et~al.}}{{Rumelhart, Hinton, and Williams}}}
\bibcite{salle2014efficient}{{20}{2014}{{Salle and Y{\i }ld{\i }zo{\u {g}}lu}}{{}}}
\bibcite{silver2016mastering}{{21}{2016}{{Silver et~al.}}{{Silver, Huang, Maddison, Guez, Sifre, Van Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot, et~al.}}}
\bibcite{srivastava2014dropout}{{22}{2014}{{Srivastava et~al.}}{{Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov}}}
\bibcite{sutskever2014sequence}{{23}{2014}{{Sutskever et~al.}}{{Sutskever, Vinyals, and Le}}}
\bibcite{szegedy2013intriguing}{{24}{2013}{{Szegedy et~al.}}{{Szegedy, Zaremba, Sutskever, Bruna, Erhan, Goodfellow, and Fergus}}}
\bibcite{williams1989learning}{{25}{1989}{{Williams and Zipser}}{{}}}
\bibcite{zhang2022sample}{{26}{2022}{{Zhang et~al.}}{{Zhang, Feng, Liu, and Wang}}}
\gdef \@abspage@last{5}
