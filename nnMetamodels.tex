\documentclass[]{article}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{inputenc}
\usepackage{amsmath, amsfonts, eucal, bbold}
\usepackage[round]{natbib}
\usepackage{amssymb}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{bm,enumitem}
\usepackage{makecell}
\usepackage{booktabs}

\DeclareMathOperator*{\argmin}{arg\,min}

\newtheorem{definition}{Definition} 
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}{Assumption}

\newcommand{\VaR}{\mbox{VaR}}
\newcommand{\CVaR}{\mbox{CVaR}}
\newcommand{\tail}{\mathcal{T}}
\newcommand{\bS}{\bm{S}}
\newcommand{\bStilde}{\widetilde{\bm{S}}}
\newcommand{\Stilde}{\widetilde{S}}
\newcommand{\Itilde}{\widetilde{I}}
\newcommand{\Ftilde}{\widetilde{F}}
\newcommand{\Gtilde}{\widetilde{G}}
\newcommand{\Vhat}{\widehat{V}}
\newcommand{\Lhat}{\widehat{L}}
\newcommand{\Deltahat}{\widehat{\Delta}}

\title{Cutting Through the Noise: Using Deep Neural Network Metamodels for High Dimensional Nested Simulation}
\author{Tony Wirjanto \and Mingbin Feng \and Xintong Li}
\date{}

\begin{document}

\maketitle

\section*{Abstract}

Deep neural network models have gained great success in many applications, but their adoption in financial and actuarial applications has been received by regulators with some trepidation.
The lack of transparency and interpretability of these models leads to skepticism about their resilience and reliability, which are important factors to ensure financial stability and insurance benefit fulfillment.
In this study, we use stochastic simulation as a data generator to examine deep neural networks under controlled settings.
Our study shows interesting findings in fundamental questions like ``What do deep neural networks learn from noisy data?'' and ``How well do they learn from noisy data?'', and the findings provides justifications for using deep neural networks in actuarial applications.
Based on our findings, we propose an efficient nested simulation procedure that uses deep neural networks as metamodels to estimate risk measures of hedging errors for variable annuities.
The proposed procedures use deep neural networks as metamodels to provide accurate loss predictions and concentrate simulation budget on tail scenarios while maintaining transparency in the estimation step, and we provide practical guidelines to extend our generic procedures for other financial and actuarial applications.

\section{Introduction}

Deep neural networks~\citep{hastie2009elements,lecun2015deep} have attracted attentions of researchers and practitioners due to their success in solving real-world supervised learning tasks such as AlphaGo~\citep{silver2016mastering} and ChatGPT~\citep{chatgpt}.
Since the first artificial neural network model~\citep{mcculloch1943logical} and the first algorithm for training a perceptron~\citep{rosenblatt1958perceptron}, especially after the introduction of backpropagation~\citep{rumelhart1985learning} and the growth of high-performance computing, the field of artificial neural network and deep learning in general has grown rapidly.
Two specialized neural network architectures that are relevant to our study are recurrent neural networks (RNNs)~\citep{williams1989learning,sutskever2014sequence} and long-short-term memory (LSTM)~\citep{hochreiter1997long,chung2014empirical}, as we need to train metamodels that take sequential observations as input.
Despite their success, deep neural network models are often criticized for their lack of transparency and interpretability, which hinders their adoption in financial and actuarial applications.
Enormous research efforts are spent to test and improve the robustness of deep neural network models with carefully designed noise injection methods.
~\cite{poole2014analyzing} show that injecting synthetic noise before and after hidden unit activations during training improves the performance of autoencoders.
~\cite{neelakantan2015adding} improve learning for deep neural networks by injecting synthetic noise to the gradients during backpropagations.
A branch of research has been devoted to understanding the resilience of neural network models to noise in training labels.
For example,~\cite{luo2016understanding} show that adding synthetic label noise to the convolutional neural network(CNN) can improve its ability to capture global features. 
~\cite{srivastava2014dropout} quantify the error tolerance by injecting synthetic label noise with a custom Boltzmann machine hardware.
~\cite{szegedy2013intriguing} find that neural networks are vulnerable to adversarial examples, and~\cite{goodfellow2014explaining} design an efficient method to generate such noisy examples to exploit the vulnerability to adversarial perturbations.
~\cite{carlini2017towards} design targeted attacks to training labels to test the robustness of neural networks. 
Instead of using synthetic noise, ~\cite{jiang2020beyond} inject real-world label noise and examine noise tolerance of neural networks with controlled noise levels.
The aforementioned studies use real-world data, as is typically the case for many neural network studies, where noise is already present in the training labels before any noise injection.
Users of real-world data have little control over the noise level of the original training labels and usually examine the effect of noisy data by injecting noise, but it is unclear whether a neural network model trained on noisy data actually learns the real, i.e., noiseless, feature-label relationship.
Due to their lack of transparency and interpretability, the adoption of deep neural networks in financial and actuarial applications has been received by regulators with some skepticism.

The contributions of our study are two-fold:
\begin{enumerate}
    \item We study what deep neural networks learn from noisy data by training them using simulated data based on well-designed simulation experiments.
    This is a novel way to study the effect of noisy data and error tolerance of neural network models as one can \textit{reduce noise} in the data by increasing the number of replications in a simulation model.
    This new way of studying neural network models can provide more direct evidence on their transparency and interpretability.  
    \item We propose two generic nested simulation procedures that uses deep neural networks as metamodels to improve its efficiency while maintaining transparency. 
    In essence, a pilot stage simulation is used to generate a large number of noisy data, which are then used to train a metamodel.
    Depending on the application, a trained metamodel can serve two purposes: (1) to identify a set of tail scenarios, and (2) to estimate risk measures directly.
    The first procedure uses a metamodel to identify a set of potential tail scenarios on which computations are performed in the second stage, while the second procedure uses metamodel predictions to estimate risk measures directly.
    Our numerical results show that deep neural network metamodels can identify the tail scenarios accurately and so the proposed procedures can estimate tail risk measures with similar accuracy while, at the same time, using less simulation budget.
\end{enumerate}

We are curious about fundamental questions like ``What do deep neural networks learn from noisy data?'' and ``How well do neural networks learn from noisy data?''.
Data-driven answers to these questions prevail in the existing literature.
In supervised learning, deep neural networks are believed to learn from the given data about the feature-label relationship to predict new labels for unseen features.
Cross validation using to assess a subset, i.e., the validation set, of the original data, is a common way to access the quality of learning.
Generalization error on the test labels is another popular assessment metric.
But the test set is also a subset of the original data.
In this study, we revisit these questions in a simulation context and propose an alternative approach to answer them.
Instead of relying solely on real-data (splitting it into multiple subsets), we propose using stochastic simulation outputs as training labels for deep neural network models.
By controlling the simulation design parameters, such as the number of independent replications, we can control the quality (and also the quantity) of the training labels fed into the neural networks.
In such a controlled environment, we obtain more clear-cut answers to the above fundamental questions.

In nested simulation, a simulation model is used to generate a large number of outer scenarios, and each scenario is then used as an input to another simulation model.
Borrowing terminologies from machine learning research, we can view a set of simulated outer scenarios and the estimated hedging errors for those scenarios as the \textit{features} and (noisy) \textit{labels}.
One can train supervised learning models using these simulated features and labels.
They are then used to replace the time-consuming inner simulations by the trained model.
We refer to the trained supervised learning models as \textit{metamodels} of the inner simulation, which is also known as the \textit{surrogate models}.
Metamodeling is a popular approach to reduce the computational burden of simulation-based applications by replacing the time-consuming simulation with a metamodel.
The metamodel is trained using a set of simulated data, and it is used to predict the simulation output for new inputs.
The study of metamodeling is an active research area in the simulation literature, and using deep neural networks as metamodels is a relatively new development.
~\cite{fonseca2003simulation} provide general guidelines for simulation metamodeling with neural networks,~\cite{lieu2022adaptive} use deep neural networks as metamodels of a simulation model for structural reliability analysis, and~\cite{salle2014efficient} show that neural network metamodels help achieve higher prediction accuracy that other metamodels in approximating agent-based simulation models.
A popular metamodel in nested simulation procedures is stochastic kriging.
~\cite{liu2010stochastic} use stochastic kriging as a metamodel of Monte Carlo simulations to estimate the Conditional Value-at-Risk (CVaR) of a portfolio of derivative securities, and~\cite{gan2015valuation} use stochastic kriging for an efficient valuation of large portfolios of variable annuity (VA) contracts.
Other studies, such as ~\cite{broadie2015risk},~\cite{hong2017kernel}, and~\cite{zhang2022sample} use regression, kernel smoothing, and the likelihood ratio method, respectively.
Our study has three key distinctions over the existing ones:
\begin{enumerate}
    \item  our metamodel has high-dimensional inputs. In machine learning terminology, the features are high-dimensional vectors.
    To estimate the hedging error of a typical VA contract, the number of features is in the order of hundreds, which is at least one order of magnitude larger than the number of features in the aforementioned studies,
    \item  for estimating tail risk measures, our metamodel is only used for tail scenario identification but is \textit{not} used in the estimation of the tail risk measures.
    This is a feature designed particularly to convince regulators that the losses used in estimating the risk measure are based on a transparent inner simulation model rather than on some black-box metamodels, and
    \item  using simulation models as data generators, we can decrease the noise level and get arbitrarily close to the true labels by increasing the number of replications in the simulation model.
    This design allows a systematic study of the effect of noisy training labels on the performance of neural network models in predicting the noiseless labels.
\end{enumerate}

The rest of this article is organized as follows: 
Section~\ref{sec:problem-formulation} presents the problem settings for tail risk measures and dynamic hedging of VAs. 
Section~\ref{sec:metamodel2Stage} proposes an efficient two-stage nested simulation procedure that uses deep neural networks as metamodels to help reduce simulation budget by only performing computations on identified tail scenarios. 
Section~\ref{sec:metamodel1Stage} proposes a one-stage nested simulation procedure that estimates risk measures directly with metamodel predictions.
Section~\ref{sec:numerical} demonstrates the efficiency of deep learning proxies and examines error tolerance of two LSTM proxy models with different numbers of trainable parameters. 
Practical suggestions are provided for the choice of suitable metamodels and simulation settings. 

\section{Problem Formulation} \label{sec:problem-formulation}

In this section we present notations, problem settings, and a simulation model for risk estimation for hedging errors of variable annuities.
A main goal of the section is to showcase the complexity of the simulation model, which we use as a data generator to train deep neural network metamodels (Section~\ref{sec:metamodel2Stage} and Section~\ref{sec:metamodel1Stage}).
For readers who are interested in the examination of a neural network metamodel, it is sufficient to understand that our simulation model generates data with 240 features and 1 real-value label and our metamodels are generally applicable to any simulation model that generates data with similar characteristics.

\subsection{Tail Risk Measures: VaR and CVaR}
Measuring and monitoring risks, particularly tail risks, are important risk management tasks for financial institutions like banks and insurance companies.
Two most popular tail risk measures are Value-at-Risk (VaR) and Conditional Value-at-Risk (CVaR)~\citep{rockafellar2002conditional}. Other names of CVaR include Conditional Tail Expectation (CTE), Tail Value-at-Risk (TailVaR), and Expected Shortfall (ES).

Consider a loss random variable $L$ whose losses and gains lie in the right and left tails, respectively, of its distribution.
For a given confidence level $\alpha\in [0,1]$, the $\alpha$-VaR is defined as the $\alpha$-quantile of $L$:
$
    \VaR_\alpha = q_\alpha = \inf \left\{ q: \Pr(L\leq q) \geq \alpha \right\}.
$
The $\alpha$-CVaR of $L$ is defined as
$
    \CVaR_\alpha =\frac{1}{1-\alpha} \int_{v=\alpha}^{1} q_v dv.
$
Tail risk measures like VaR and CVaR are widely used for setting regulatory and economic capital, which is the amount of capital a financial institution holds to cover its risk.
For example, European insurers set regulatory capital at $99.5\%$-VaR according to Solvency II~\cite{eiopa2014underlying}.
In Canada, the regulatory capital requirement for VAs is set based on CVaRs as prescribed in~\cite{osfi2017life}.

Let $L_1,L_2,\ldots,L_M$ be $M$ independent and identically distributed (i.i.d.) simulated losses of $L$ and let $L_{(1)}\leq L_{(2)}\leq \ldots\leq L_{(M)}$ be the corresponding ordered losses.
For a given confidence level $\alpha$ (assume that $\alpha M$ is an integer for simplicity), $\alpha$-VaR can be estimated by the sample quantile $\widehat{\VaR}_\alpha = L_{(\alpha M)}$. Also, $\alpha$-CVaR can be estimated by
\begin{equation*}
    \widehat{\CVaR}_\alpha = \frac{1}{(1-\alpha)M} \sum_{i=\alpha M + 1}^{M}L_{(i)} = \frac{1}{(1-\alpha)M} \sum_{i \in \tail_{(1-\alpha )M}}L_{i},
\end{equation*}
where we define a \textit{true tail scenario set} of size $k$ as $\tail_{k} = \{i: L_i > L_{(M-k)}\}$.
In this study, the loss random variable of interest is the hedging error for VA.

\subsection{Simulation Model for Variable Annuity Payouts}\label{subsec:VApayout}

Variable annuity contracts offer different types of guarantees.
Generally speaking, a portion of the VA premium is invested in a sub-account whose return is linked to some stock indices.

Two relevant types of guarantees in our studies are:
\begin{itemize}[noitemsep]
    \item \textbf{Guaranteed Minimum Maturity Benefit (GMMB)}: A GMMB contract pays a maturity benefit equal to the greater of the sub-account value and a fixed guarantee value.
    The guarantee value is often set as a percentage, e.g., 75\% or 100\%, of the initial premium.

    \item \textbf{Guaranteed Minimum Withdrawal Benefit (GMWB)}: A GMWB contract guarantees the minimum amount of periodic withdrawal the policyholder can take from the sub-account until maturity, even if the sub-account value reduces to zero.
    The minimum withdrawal benefit is typically a fixed percentage of the guarantee value.
    The guarantee value will decrease if the withdrawal exceeds the guaranteed minimum. The GMWB is typically offered with an accumulation period, during which no withdrawals are made but a GMDB is usually offered. Additional features offered with the GMWB include roll-up, ratchet, and reset~\citep{geneva2013variable}.
\end{itemize}
For a comprehensive review of other types of VA contracts such as Guaranteed Minimum Death Benefit (GMDB), Guaranteed Minimum Accumulation Benefit (GMAB) and Guaranteed Lifetime Withdrawal Benefit (GLWB), we refer readers to~\cite{hardy2003investment}.
Next we present a summary of dynamic hedging for VA contracts.
We refer readers to~\cite{dang2021efficient} for detailed modeling of insurer liabilities in different VA contracts and Greek estimation.

Consider a generic VA contract with maturity $T>0$ periods, e.g., $T=240$ months.
Denote the policyholder's (random) time of death by $\tau>0$.
Then the contract expires at $T'=\min\{T,\tau\}$, i.e., the earlier of the contract maturity and the death of the policyholder.
Let $S_t$, $F_t$, and $G_t$ be the indexed stock price, the subaccount value and the guarantee value, respectively, at time $t=1,2,\ldots,T$.
Evolution of the subaccount value and the guarantee value of a VA contract affect the contract payout.
Note that the policyholder's (random) time of death also affects the timing of the benefit payout for certain types of VA such as GMDB, but this is not considered in our study for simplicity.
For clarity, we use $F_t$ and $F_{t_+}$ to denote the sub-account value just before and just after the withdrawal at time $t$, if any.
Let $\eta_g$ be the gross rate of management fee that is deducted from the fund value at each period and let $\eta_n < \eta_g$ be the net rate of management fee income to the insurer.
The difference between the gross management fee and the net management fee income represents the incurred investment expenses.

At the inception of the contract, i.e., $t=0$, we assume that the whole premium is invested in the stock index and the guarantee base is set to the sub-account value:
\begin{equation*}
    S_0=F_0=G_0.
\end{equation*}
At each time $t=1,\ldots,T$, the following events take place in the following order:
\begin{enumerate}
    \item The sub-account value changes according to the growth of the underlying stock and the (gross) management fee is deducted. That is, 
        \begin{equation*}
            F_t = F_{(t-1)_+}\cdot\frac{S_{t}}{S_{t-1}}\cdot(1-\eta_g),
        \end{equation*} 
    where $(x)^+=\max\{x,0\}$ and $F_{(t-1)_+}$ will be defined later. The insurer's income at time $t$ is the net management fee, i.e., $F_t\eta_n$. 

    \item The guarantee value ratchets up (ratcheting is a common feature in GMWB) if the sub-account value exceeds the previous guarantee value, i.e., 
        \begin{equation*}
            G_t = \max\{G_{t-1},F_t\}.
        \end{equation*} 

    \item The withdrawal is made (for GMWB) and is deducted from the sub-account value, i.e., 
        \begin{equation*}
            F_{t_+} = (F_t - I_t)^+,
        \end{equation*} 
    where $I_t = \gamma G_t$. A GMMB can be modeled with $\gamma = 0$.
\end{enumerate}

We see from the above modeling steps that the status of a generic VA contract is summarized by a triplet $(S_t,F_t,G_t)$ whose evolution is driven by the stochasticity of $S_t$.
In practice, the simulation model may also incorporate additional complications like mortality, lapse, and excess withdrawal, etc.

At any time $t=1,\ldots,T$, the insurer's liability in a VA contract is the present value of all payments, net of the fee income.
For example, suppose that the per-period risk-free rate is $r$, then
the insurer's time-$t$ liability for a GMMB contract is $V_t = e^{-r(T-t)}\cdot (G_T - F_T)^+ - \sum_{s=t+1}^{T} e^{-r(T-s)} F_s \eta_n$.
Also, the insurer's time-$t$ liability for a GMWB contract is $V_t = \sum_{s=t+1}^{T} e^{-r(T-s)} [(I_s - F_s)^+- \eta_n F_s] $.

For example, consider the time-$t$ liability $V_t$ of a GMWB:
Suppose that given the stock sample path, e.g., an outer path $S_1,\ldots,S_t$, one can simulate future stock prices $\Stilde_{t+1},\ldots,\Stilde_{T}$, e.g., inner sample paths, based on some asset model such as a Black-Scholes model.
The tilde symbol ($\sim$) over a quantity denotes its association with the inner simulation.
Given the time~$t$ state $(S_t,F_t,G_t)$, following~\cite{cathcart2015calculating} the sensitivity of $V_t$ with respect to $S_t$ can be estimated by a pathwise estimator~\citep{glasserman2004monte}:
\begin{equation}\label{eq:delta}
    \Delta_t(\Stilde_{t+1},\ldots,\Stilde_{T} | S_t) = \frac{\partial V_t}{\partial S_t} = \sum_{s=t+1}^{T} e^{-r(T-s)} \left[\bm{1}\{\Itilde_s > \Ftilde_s\}\cdot \left( \frac{\partial \Itilde_s}{ \partial S_t} - \frac{\partial \Ftilde_s}{ \partial S_t}\right)- \eta_n \frac{\partial \Ftilde_s}{ \partial S_t}\right], \quad t=0,\ldots,T-1,
\end{equation}
where $\bm{1}\{\cdot\}$ is an indicator function and
\begin{align*}
    \frac{\partial \Ftilde_s}{ \partial S_t} &= \bm{1}\{\Itilde_{s-1} < \Ftilde_{s-1}\}\cdot\left( \frac{\partial \Ftilde_{s-1}}{ \partial S_t} - \frac{\partial \Itilde_{s-1}}{ \partial S_t}\right) \cdot \frac{\Stilde_s}{\Stilde_{s-1}}\cdot (1-\eta_g),\\
    \frac{\partial \Gtilde_s}{ \partial S_t} &= \bm{1}\{\Gtilde_{s-1} < \Ftilde_{s}\}\cdot\frac{\partial \Ftilde_{s}}{ \partial S_t} + \bm{1}\{\Gtilde_{s-1} \geq \Ftilde_{s}\}\cdot\frac{\partial \Gtilde_{s-1}}{ \partial S_t},\\
    \frac{\partial \Itilde_s}{ \partial S_t} &= \gamma \frac{\partial \Gtilde_s}{ \partial S_t}.
\end{align*}
The recursion is initialized with $(\Stilde_t,\Ftilde_t,\Gtilde_t) = (S_t,F_t,G_t)$, $\frac{\partial \Ftilde_s}{ \partial S_t} = \frac{\Ftilde_t}{S_t}$, and $\frac{\partial \Gtilde_s}{ \partial S_t} = \frac{\partial \Itilde_s}{ \partial S_t} = 0$.


\subsection{Dynamic Hedging for Variable Annuities}\label{subsec:dynamicHedge}

Below we provide a scheme used to perform a multi-period nested simulation in estimating (profit and loss) P\&L for one outer scenario.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\textwidth]{./figures/figure.pdf}
    \caption{Illustration of multi-period nested simulation that estimates the P\&L for one outer scenario.}
    \label{fig:illustration}
\end{figure}

Insurers commonly use dynamic hedging to mitigate a market risk exposure in VA contract's embedded options.
In a dynamic hedging program, a hedge portfolio is set up and periodically rebalanced for a portfolio of VA contracts using stocks, bonds, futures, and other derivatives.
For simplicity, in this study we consider delta hedging for a generic VA liability using one stock and one bond.
The metamodeling procedures in Section~\ref{sec:metamodel2Stage} and Section~\ref{sec:metamodel1Stage} can be trivially adapted to more general hedging strategies.

Consider a generic VA contract whose delta hedge portfolio at any time~$t$, $t=0,1,\ldots,T-1$, consists of $\Delta_t$ units in the underlying stock and $B_t$ amount of a risk-free zero-coupon bond maturing at time $T$.
The value of the hedge portfolio at time~$(t-1)$ is:
\begin{equation*}
    H_{t-1} = \Delta_{t-1} S_{t-1} + B_{t-1},
\end{equation*}
where $S_t$ is the underlying stock price and any time $t>0$.
This hedge portfolio is brought forward to the next rebalancing time~$t$, when its value becomes:
\begin{equation*}
    H_{t}^{bf} = \Delta_{t-1} S_{t} + B_{t-1}e^{r}.
\end{equation*}
Therefore, the time~$t$ hedging error, i.e., the cash flow incurred by the insurer due to rebalancing at time~$t$, is
\begin{equation}\label{eq:hedgingerror}
    HE_t = H_t - H^{bf}_t, \quad t=1,\ldots, T-1.
\end{equation}
The P\&L of the VA contract includes the cost of the initial hedge ($H_0$), the hedging errors~\eqref{eq:hedgingerror}, the unwinding of the hedge at maturity ($H^{bf}_T$), and the unhedged liability ($V_0$).
Mathematically, the present value of these cash flows is given by
\begin{equation}\label{eq:lossrv}
L = H_0 + \sum_{t=1}^{T-1} e^{-rt} HE_t - e^{-rT} H^{bf}_T + V_0 = \sum_{t=0}^{T-1}\Delta_t (e^{-rt}S_t - e^{-r(t+1)}S_{t+1}) + V_0,
\end{equation}
where the second equality holds by a telescopic sum simplification of $e^{-rt}B_t$, $t=0,\ldots,T-1$.

In~\eqref{eq:lossrv}, $\Delta_t$ and $V_0$ are determined by using a risk-neutral measure $\mathbb{Q}$ while the distribution of $L$ is under a real-world measure $\mathbb{P}$.
If $\Delta_t$ and $V_0$ cannot be calculated analytically, a nested simulation is required to estimate the tail risk measure of $L$.
Recall from Section~\ref{subsec:VApayout} that the stock sample path, regardless of the inner or outer simulation or a combination of both, determines the evolution of the triplet $(S_t,F_t,G_t)$.
Specifically, the outer scenarios $\bS^{(i)} = (S_{1}^{(i)},\ldots,S_{T}^{(i)})$, $i=1,\ldots,M$ are generated under $\mathbb{P}$.
At each time~$t=1,\ldots,T-1$ of a given outer scenario $\bS^{(i)}$, inner sample paths $\bStilde_{t}^{(j)} = (\Stilde_{t+1}^{(j)},\ldots,\Stilde_{T}^{(j)})$, $j=1,\ldots,N$ are generated under $\mathbb{Q}$ to estimate $\Delta_t^{(i)}$, $i=1,\ldots,M$.
Also, $V_0^{(i)}$, $i=1,\ldots,M$ are estimated under $\mathbb{Q}$ via inner simulations at time $0$.
Recall from Section~\ref{subsec:VApayout} that the stock's sample path, regardless of inner or outer simulation or a combination of both, determines the evolution of the triplet $(S_t,F_t,G_t)$.
For example, for GMWB, a standard nested simulation procedure to estimate the $\alpha$-CVaR of $L$ is as follows:
\begin{enumerate}
    \item For $i=1,\ldots,M$, simulate outer scenarios $\bS^{(i)} = (S_{1}^{(i)},\ldots,S_{T}^{(i)})$ under the real-world measure $\mathbb{P}$.
    Figure~\ref{fig:illustration} illustrates the inner simulation experiments needed for an outer scenario.
    
    \item For $t=0$, simulate time-$0$ inner paths $\bStilde_{0}^{(j)} = (\Stilde_{1}^{(j)},\Stilde_{2}^{(j)},\ldots,\Stilde_{T}^{(j)})$, $j=1,\ldots,N$ under $\mathbb{Q}$ {and} then estimate $V_0$ by $\Vhat_0 = \sum_{s=1}^{T} e^{-r(T-s)} [(I_s - F_s)^+- \eta_n F_s]$ and estimate $\Deltahat_0 = \Delta_0(\Stilde_{1}^{(j)},\ldots,\Stilde_{T}^{(j)} | S_0)$ based on~\eqref{eq:delta}.
    Note that $S_0$ is known, so these inner paths do not depend on any outer scenario.
    The same $\Vhat_0$ and $\Deltahat_0$ are used in all scenarios.
    
    \item Given each scenario $\bS^{(i)}$, the following inner simulation is needed to estimate the corresponding loss $\Lhat_i$ for that scenario.
    \begin{enumerate}
        \item At each time~$t=1,\ldots,T-1$, simulate inner paths $\bStilde_{t}^{(ij)} = (\Stilde_{t+1}^{(ij)},\ldots,\Stilde_{T}^{(ij)})$, $j=1,\ldots,N$ under $\mathbb{Q}$ {and} then estimate $\Delta_t$ by $\Deltahat_t^{(i)} = \Delta_t(\Stilde_{t+1}^{(ij)},\ldots,\Stilde_{T}^{(ij)} | \bm{S}_t^{(i)})$ based on~\eqref{eq:delta}.

        \item Use scenarios $\bS^{(i)}$ and $\Vhat_0$ and $\Deltahat_t^{(i)}$ to calculate losses $\Lhat_i^{MC}$, $t=0,\ldots,T-1$, based on~\eqref{eq:lossrv}. Then sort them as $\Lhat^{MC}_{(1)}\leq \Lhat^{MC}_{(2)} \leq \cdots\leq \Lhat^{MC}_{(M)}$.
    \end{enumerate}

    \item Estimate $\alpha$-CVaR of $L$ by $\widehat{\CVaR}^{MC}_\alpha = \frac{1}{(1-\alpha)M} \sum_{i=\alpha M + 1}^{M}\Lhat_{(i)}^{MC} = \frac{1}{(1-\alpha)M} \sum_{i \in \widehat{\tail}_{(1-\alpha )M}^{MC}}\Lhat_{i}^{MC}$
where $\widehat{\tail}_{k}^{MC}$ denotes {a} \textit{Monte Carlo tail scenario set} associated with the largest $k$ estimated losses.
\end{enumerate}

We refer to the collection of experiments needed conditional on one scenario $\bS^{(i)}$ to estimate $L_i$, that is, all upward arrows in Figure~\ref{fig:illustration}, as one inner simulation experiment.
We make four observations:
\begin{itemize}
    \item   each inner simulation is time-consuming, as it includes $T$ simulation experiments, one at each time $t=0,\ldots,T-1$,
    \item   after running inner simulations for $M$ scenarios, we obtain simulated data, that is, feature-label pairs, $(\bS^{(i)}, \Lhat_i)$, $i=1,\ldots,M$; the feature vector $\bS$ is $T$ dimensional,
    \item   $\Lhat_i^{MC}$ is a standard Monte Carlo estimator of the true loss for scenario $\bS^{(i)}$. It is an unbiased estimator and its variance is inversely proportional to the number of inner replications $N$. 
    As $N$ approaches infinity, $\Lhat_i^{MC}$ converges to the true loss $L_i$, and
    \item   most importantly, when estimating tail risk measures such as $\alpha$-CVaR, only a small number of estimated losses, that is, those associated with the set of tail scenarios $\widehat{\tail}_{k}$ are used in the estimator.
\end{itemize}

\section{Two-Stage Nested Simulation with Metamodels} \label{sec:metamodel2Stage}

Based on the three observations above and inspired by~\cite{dang2020efficient}, we propose a two-stage nested simulation procedure which uses a deep neural network metamodel to identify potential tail scenarios.
We present our proposed procedure as a competitor to the standard procedure with $M$ outer scenarios and $N$ inner replications for each outer scenario, as described in Section~\ref{subsec:dynamicHedge}.
We propose a two-stage procedure with a neural network metamodel that aims to produce a CVaR estimate that's as accurate as that of the standard procedure, but uses less computations as than latter.
An overview of the proposed procedure is as follows:

\begin{itemize}
    \item[I.] \textbf{Train a neural network metamodel using simulation data.}
    \begin{itemize}[leftmargin=0pt]
        \item Use a fraction of the total simulation budget to run Steps 1, 2, and 3 in the standard procedure with the same number of outer scenarios, $M$, but a much smaller number of inner replications, i.e., $N'\ll N$, in each scenario.
        Then obtain $M$ simulated samples, i.e., feature-label pairs, $(\bS^{(i)}, \Lhat_i)$, $i=1,\ldots,M$.
        Note that $N'$ may be 10 times or even 100 times smaller than $N$, so the loss estimates $\Lhat_i$ are expected to have larger variance, i.e., more noisy, than the standard procedure's loss estimates.
    
        \item Use the simulated data, $(\bS^{(i)}, \Lhat_i)$, $i=1,\ldots,M$ to train a neural network.
        We refer to the trained model as a \textit{metamodel} as denote it by $\Lhat^{PD}(\bS)$.
        Denote the predicted losses for the outer scenarios by $\Lhat^{PD}_i = \Lhat^{PD}(\bS^{(i)})$, $i=1,\ldots,M$.
    
        \item Sort the predicted losses $\Lhat^{PD}_{(1)}\leq \Lhat^{PD}_{(2)} \leq \cdots\leq \Lhat^{PD}_{(M)}$ to identify a \textit{predicted tail scenario set} associated with the largest predicted losses, i.e., $\widehat{\tail}_{m}^{PD}:=\{i: \Lhat^{PD}_i > \Lhat^{PD}_{(M-m)}\}$.
        The number of predicted tail scenarios, $m$, is a user's choice and will be discussed later.
    \end{itemize}
        \item[II.] \textbf{Concentrate simulation on predicted tail scenarios.}
        \begin{itemize}[leftmargin=0pt]
        
        \item Run Steps 2 and 3 of the standard procedure with the same number of inner replications, $N$, but only on the predicted tail scenarios, i.e., scenarios associated with $\widehat{\tail}_{m}^{PD}$.
        Denote the standard procedure's estimated losses and sorted losses by $\Lhat^{ML}_i$ and $\Lhat^{ML}_{(i)}$, respectively, $i=1,\ldots,m$.
        
        \item Estimate the $\alpha$-CVaR of $L$ by $\widehat{\CVaR}^{ML}_\alpha = \frac{1}{(1-\alpha)M} \sum_{i=\alpha M + 1}^{M}\Lhat_{(i)}^{ML} = \frac{1}{(1-\alpha)M} \sum_{i \in \widehat{\tail}_{(1-\alpha )M}^{ML}}\Lhat_{i}^{ML}$
        where $\widehat{\tail}_{k}^{ML}$ denotes a \textit{predicted tail scenario set} associated with the largest $k$ estimated losses.
    \end{itemize}
    \end{itemize}
    
Similar to~\cite{dang2020efficient}, the proposed two-stage procedure uses the metamodel predictions to identify the predicted tail scenario set in Stage I.
But, different from their fixed-budget simulation design, we attempt to achieve a target accuracy.
Specifically, in Stage II we propose using a standard procedure with the same number of inner replications, $N$, as a competing simulation procedure (or a benchmark).
There are two different experiment designs for nested simulation procedures: fixed-budget design and fixed-accuracy design.
In a fixed-budget design, the simulation budget is fixed and the goal is to achieve the highest accuracy possible within the budget.
Let $\Gamma = MN$ be the simulation budget for the standard procedure, where each scenario receives $\frac{\Gamma}{M}$ inner replications.
In the proposed two-stage procedure, suppose Stage I uses 1\% of the simulation budget, $\alpha = 95\%$, and $m=(1-\alpha)M$, then $99\%$ of the simulation budget is concentrated on $5\% M$ predicted tail scenarios in Stage II.
In other words, each predicted tail scenario receives $\frac{99\% \Gamma}{5\% M}$ inner replications, almost 20 times more than that in the standard procedure.
This budget concentration is expected to improve the estimation accuracy of the two-stage procedure compared to a standard procedure with the same budget. 
If the metamodel is accurate in predicting true tail scenarios, then the two-stage procedure is expected to achieve higher accuracy than the standard procedure with the same budget.
However, we believe that the goal of designing an efficient simulation procedure is to solve practical problems faster, so a target-accuracy design is more suitable, which refers to obtaining a similar level of accuracy as the standard procedure but with much less simulation budget.
One other reason for this fixed-accuracy design is to investigate whether deep neural network metamodels trained with much noisier labels can identify true tail scenarios with similar accuracy as the standard procedure.
The size of the predicted tail scenario set in Stage I, $m$, is an important experiment design parameter that affects the correct identification of true tail scenarios and ultimately affects the estimation accuracy for CVaR.
Clearly, there is a lower bound $m \geq (1-\alpha)M$ because the $\alpha$-CVaR is estimated by the average of $(1-\alpha)M$ largest losses at the end of Stage II.
For ease of reference, we call the additional percentage of predicted tail scenarios above this lower bound, i.e., $\epsilon = \frac{m - (1-\alpha)M}{M}$, as a \textit{safety margin}.
On one hand, large $\epsilon$ is not desirable because it increases computations in Stage II.
On the other hand, $\epsilon$ should be set reasonably large so more true tail scenarios are included in the the predicted tail scenario set $\widehat{\tail}_{m}^{PD}$ and are ultimately included in $\widehat{\tail}_{(1-\alpha )M}$ at the end of Stage II.
The selection of $m$ is highly dependent on the choice of the metamodel.
Due to the simulation errors and approximation error in the metamodel in Stage I, we do not expect perfect match between the true tail scenario set $\tail_{k}$ and the proxy tail scenario set $\widehat{\tail}_{k}^{PD}$ for any size $k$.
This means that we should not set $m$ at its lower bound: Some safety margin $\epsilon M$ should be added to the proxy tail scenario set, i.e., $m = (1-\alpha )M + \epsilon M$, to increase the likelihood that $\tail_{k} \subseteq \widehat{\tail}_{m}^{PD}$ and that the true tail scenarios are included in estimating $\alpha$-CVaR at the end of Stage II.
In the numerical experiments, we examine the relationship between the safety margin and the correct identification of true tail scenarios for different metamodels.

\section{One-Stage Nested Simulation with Neural Network Metamodels} \label{sec:metamodel1Stage}

In our numerical experiment of the two-stage procedure, we observe that a suitable metamodel trained with noisy labels is accurate enough to identify true tail scenarios with a relatively small safety margin.
This observation motivates us to propose a one-stage procedure that uses the same neural network metamodel to estimate the CVaR directly with the predicted losses. 
An overview of the single-stage procedure is as follows:

\begin{itemize}
    \item[I.] \textbf{Train a neural network metamodel using simulation data.}
    \begin{itemize}[leftmargin=0pt]
        \item 
    \end{itemize}
    \item[II.] \textbf{Estimate CVaR using predicted losses.}
    \begin{itemize}[leftmargin=0pt]
        
        \item Run Steps 2 and 3 of the standard procedure with the same number of inner replications, $N$,
    \end{itemize}
        
\end{itemize}
\section{Numerical Results} \label{sec:numerical}

We conduct a series of simulation experiments to (1) demonstrate the efficiency of the proposed metamodeling procedures and (2) examine the error tolerance to noisy training data in deep learning models.
The problem settings in our experiments are identical to those in~\cite{dang2020efficient}:
we consider estimating the $95\%$ CVaR of the hedging loss of a GMWB contract, which is one of the most complex VA contracts in the market.
The VA contracts have a 20-year maturity and are delta-hedged with monthly rebalancing, i.e., $T=240$ rebalancing periods.
The gross and net management fees are $\eta_g = 0.2\%$ and $\eta_n=0.1\%$, respectively.
The withdrawal rate for GMWB is $0.375\%$ per month.
% To make our examples more realistic, the VAs are also subject to dynamic lapse as specified in Section~4.3 of~\cite{dang2020efficient}.
The risk-free rate is 0.2\% per period and the underlying asset $S_t$ is modeled by a regime-switching geometric Brownian motion with parameters specified in Table~2 of~\cite{dang2020efficient}.

To compare the numerical performances of different simulation procedures, we create a benchmark dataset with a large-scale nested simulation: We first simulate $M=100\!,\!000$ outer scenarios, i.e., $240$-periods stock paths $\bS^{(1)},\ldots,\bS^{(M)}$ under $\mathbb{P}$ and used these outer scenarios in all further experiments.
Note that the 5\% tail scenario set includes $5\!,\!000$ scenarios.
As the hedging losses for these scenarios cannot be calculated analytically, we run inner simulations with a large number of replications, $N=100\!,\!000$, conditional on each of the $M$ scenarios.
We denote these losses by $L_1,\ldots,L_M$ and will refer to them as \textit{true losses}.
We also use these true losses to estimate $\widehat{\CVaR}_{95\%}$ and denote the corresponding \textit{true tail scenario set} by $\tail_{5000}$.
Lastly, we refer to the set of feature-label pairs $\{(\bS^{(i)}, L_i): i=1,\ldots,M\}$ as a \textit{true dataset}.
Note that the feature vector $\bS$ is a 240-dimension stock path.

We compare our two-stage procedure to a standard nested simulation procedure that runs $N=1\!,\!000$ inner replications for each of the $M=100\!,\!000$ outer scenarios.
In Stage I of the proposed procedure, we first run inner simulations with $N'=100$ inner replications for each of the $M=100\!,\!000$ outer scenarios.
So, Stage I's simulation budget is $10\%$ of the standard procedure's.
The resulting feature-label pairs $\{(\bS^{(i)}, \Lhat_i): i=1,\ldots,M\}$ is used for training different  metamodels.
Specifically, following the convention in machine learning research, we split this dataset into three parts: The training, validation, and test sets have $90\!,\!000$, $5\!,\!000$, and $5\!,\!000$ data points (90\%, 5\%, and 5\% of the dataset), respectively.
At the end of Stage I, $m$ predicted tail scenarios, are identified by the trained metamodels.
In Stage II, $N=1\!,\!000$ inner replications are run for all predicted tail scenarios.
Stage II's simulation budget is $\frac{m}{M}$ of the standard procedure's.
In short, the two-stage procedure uses $15\% - 30\%$ of the standard procedure's budget for a safety margin between $0\% - 15\%$.

Five metamodels are considered in this experiment: multiple linear regression (MLR), quadratic polynomial regression (QPR) without interaction terms, feed-forward neural network (FNN), recurrent neural network (RNN), and long short-term memory (LSTM) network.
MLR and QPR are considered as extensions of regression metamodels in the nested simulation literature.
FNN is a generic neural network while RNN and LSTM are specialized models to accommodate the sequential structure of our time-series features.
A $\tanh$ activation function is used for RNN and LSTM layers, and a Rectified Linear Unit (ReLU) activation function is used for the fully-connected layers.
All neural network metamodels are trained by the Adam optimizer~\citep{kingma2014adam} with an initial learning rate of $0.001$ and an exponential learning rate decay schedule.
FNN is trained with a dropout rate of 20\%.
RNN and LSTM are trained with a dropout rate of 10\%.
The architectures and training settings are typical choices in the deep learning literature.
The training labels are normalized to have zero mean and unit standard deviation.
The architectures and the numbers of trainable parameters are shown in the first two columns of Table~\ref{tab:gmwb_arch}.
We see that the three deep neural network metamodels' have orders of magnitudes more trainable parameters than the two regression models.
In machine-learning terminologies, the three deep neural network models have much higher \textit{model capacities}.

\begin{table}[ht!]
    \small
    \centering
    \begin{tabular}{lccccccc}
        \toprule
        \textbf{Model} & \textbf{\makecell{Layer size}} & \textbf{\makecell{\# parameters}} & \textbf{Training errors} & \textbf{Test errors} & \textbf{True errors}\\
        \midrule
        MLR     & N/A                       & 241          & $0.7075$ & $0.6885$ & $0.6932$ \\
        QPR     & N/A                       & 481          & $0.5415$ & $0.5411$ & $0.5294$ \\
        FNN     & $240, 128, 16$            & $35\!,\!009$ & $0.2119$ & $0.3053$ & $0.2089$ \\
        RNN     & $(240, 32), (240, 4), 32$ & $32\!,\!021$ & $0.1264$ & $0.1702$ & $0.1198$ \\
        LSTM    & $(240, 32), (240, 4), 32$ & $35\!,\!729$ & $0.0902$ & $0.0958$ & $0.0789$ \\
        \bottomrule
    \end{tabular}
    \caption{Architectures and MSEs of metamodels for GMWB inner simulation model.}
    \label{tab:gmwb_arch}
\end{table}

The last three columns in Table~\ref{tab:gmwb_arch} display the average squared errors between the predicted losses and the losses (labels) in different datasets.
We first observe that the two regression metamodels' errors are larger than those of three deep neural network models.
This is because model capacities of the regression metamodels are too low to learn the complex dynamic hedging simulation model.
There are also differences among the three deep neural network models.
The FNN is a generic neural network, its test error is larger than the training error, which is a sign of over-fitting and poor generalization.
In contrast, RNN and LSTM are networks designed to capture temporal relationship in the high-dimensional feature.
As a result, they have lower training errors, i.e., they fit the data better, and have lower testing error, i.e., they generalize better.
Notably, the true errors for the deep neural network metamodels are lower than the test errors.
Recall that all three data sets are generated from the same simulation model, but the true data set is less noisy than the training and test data.
Part of the test error is due to simulation noise, and this noise is lower in the true error.
We observe that the two regression metamodels not only generalize to the test data poorly but also generalize to the true data poorly.
In contrast, the deep neural network metamodels generalize better to the true data than to the test data.
This implies that these models indeed learn the true feature-label relationship in the dynamic hedging simulation model (i.e., true data) even though they are trained on noisy observations (e.g., training data) of the model.
      
\subsection{Two-Stage Procedure}

\subsection{One-Stage Procedure}

\section{Conclusion} \label{sec:conclusion}
The proposed nested simulation procedures with deep neural network metamodels result in substantial computational savings in estimating CVaR of the hedging loss of a VA contract from accurately predicting the hedging losses and identifying the tail scenarios.
An LSTM trained with noisy training labels is able to cut through the noise and learn the true complex dynamic hedging model.
When new outer scenarios are generated, a trained metamodel can distinguish between tail and non-tail scenarios and make accurate predictions without the need to run new inner simulations.


\newpage
\bibliographystyle{plainnat}
\footnotesize
\bibliography{refP2}



\end{document}
